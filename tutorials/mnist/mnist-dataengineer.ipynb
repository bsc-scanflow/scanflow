{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist DataEngineer (Inference Stage)\n",
    "\n",
    "****DataEngineerTeam****: Responsible for deploying the machine learning model by using batch workflows or online model serving, and managing the inference workflow or service\n",
    "- *Steps*\n",
    "    1. Import Scanflow and check the local environment\n",
    "    2. Develop scanflow application (workflows, agents)\n",
    "    3. Build scanflow application\n",
    "    4. Deploy scanflow environment\n",
    "    5. Download production models\n",
    "    6. Submit the metadata and artifacts to the central Scanflow-tracker\n",
    "    7. ****[Inference]****\n",
    "        1. Batch-inference (Argo)\n",
    "        2. Online-inference (Seldon)\n",
    "    **(step7 can be auto-managed by MAS)**\n",
    "    8. Clean environment\n",
    "- *Deliverables*\n",
    "    1. Built scanflow application metadata\n",
    "    2. DataEngineerTeam artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "### Step1: Import Scanflow and check the local environment\n",
    "1. import scanflow\n",
    "    - For defining and building scanflow application, we need to import ScanflowClient\n",
    "    - For deploying scanflow application, we need to import ScanflowDeployerClient\n",
    "    - For saving artifacts, we need to import ScanflowTrackerClient\n",
    "2. check local environment\n",
    "    - For deploying scanflow application\n",
    "        - If user starts the notebook at local and has the privilege to submit object on Kubernetes. We don't need to configure \"SCANFLOW_SERVER_URI\"\n",
    "        - If user starts the notebook inside Kubernetes pod, or the local user does not have privilege to connect Kubernetes. We need to configure \"SCANFLOW_SERVER_URI\"\n",
    "    - For saving deliverables, we need to configure url of Scanflow-tracker on \"SCANFLOW_TRACKER_URI\" and url of Scanflow-local-tracker on \"SCANFLOW_TRACKER_LOCAL_URI\"\n",
    "    - If Scanflow-tracker is using S3 artifact storage, we need to configure S3 url \"MLFLOW_S3_ENDPOINT_URL\", username \"AWS_ACCESS_KEY_ID\" and password \"AWS_SECRET_ACCESS_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'../..')\n",
    "\n",
    "import scanflow\n",
    "from scanflow.client import ScanflowClient\n",
    "from scanflow.client import ScanflowTrackerClient\n",
    "from scanflow.client import ScanflowDeployerClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://172.30.0.50:46666\n",
      "http://172.30.0.50:46667\n",
      "http://172.30.0.50:43447\n",
      "admin\n",
      "admin123\n"
     ]
    }
   ],
   "source": [
    "from scanflow.tools import env\n",
    "print(env.get_env(\"SCANFLOW_SERVER_URI\"))\n",
    "print(env.get_env(\"SCANFLOW_TRACKER_URI\"))\n",
    "#print(env.get_env(\"SCANFLOW_TRACKER_LOCAL_URI\"))\n",
    "print(env.get_env(\"MLFLOW_S3_ENDPOINT_URL\"))\n",
    "print(env.get_env(\"AWS_ACCESS_KEY_ID\"))\n",
    "print(env.get_env(\"AWS_SECRET_ACCESS_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Develop scanflow application\n",
    "\n",
    "  1. develop component (requirement.txt, script.py)\n",
    "  2. define scanflow workflows (Executor, Dependency, Workflow)\n",
    "  3. define agents to supervise the workflows\n",
    "  4. define scanflow application\n",
    "  ```bash\n",
    "     Application\n",
    "        - List: Workflow(DAG)\n",
    "                  - List: Executor\n",
    "                  - List: Dependency\n",
    "        - List: Agents(Web Services)\n",
    "  ```\n",
    "  \n",
    "  \n",
    "     For example:\n",
    "     \n",
    "  ```bash\n",
    "  mnist\n",
    "    - workflows\n",
    "       - load_data\n",
    "         - loaddata.py\n",
    "       - predictor-batch\n",
    "         - predictor.py\n",
    "       - detector-batch\n",
    "         - checker.py\n",
    "       - pick-data\n",
    "         - pick-data.py\n",
    "    - agents\n",
    "       - tracker\n",
    "       - checker\n",
    "       - improver\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Develop scanflow workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App folder\n",
    "scanflow_path = \"/gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow\"\n",
    "app_dir = os.path.join(scanflow_path, \"examples/mnist/dataengineer\")\n",
    "app_name = \"mnist\"\n",
    "team_name = \"dataengineer\"\n",
    "\n",
    "# scanflow client\n",
    "client = ScanflowClient(\n",
    "              #if you defined \"SCANFLOW_SERVER_URI\", you dont need to provide this\n",
    "              #scanflow_server_uri=\"http://172.30.0.50:46666\",\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor\n",
    "executor1 = client.ScanflowExecutor(name='load-data', \n",
    "                      mainfile='loaddata.py',\n",
    "                      parameters={'app_name': app_name,\n",
    "                                  'team_name': 'data'})\n",
    "\n",
    "executor2 = client.ScanflowExecutor(name='predictor-batch', \n",
    "                      mainfile='predictor.py',\n",
    "                      parameters={'model_name': 'mnist_cnn',\n",
    "                                  'input_data': '/workflow/load-data/mnist/data/mnist_sample/test_images.npy', },\n",
    "                      base_image='modeling-cnn1')\n",
    "\n",
    "\n",
    "dependency1 = client.ScanflowDependency(dependee='load-data',\n",
    "                                    depender='predictor-batch')\n",
    "\n",
    "##workflow1 batch-inference\n",
    "## -- load_data\n",
    "##       -- predictor-batch\n",
    "workflow1 = client.ScanflowWorkflow(name='batch-inference', \n",
    "                     executors=[executor1, executor2],\n",
    "                     dependencies=[dependency1],\n",
    "                     output_dir = \"/workflow\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checker workflow\n",
    "executor3 = client.ScanflowExecutor(name='load-data', \n",
    "                      mainfile='loaddata.py',\n",
    "                      parameters={'experiment_name': 'checker',\n",
    "                                  'run_id': '',\n",
    "                                  'path': 'data'})\n",
    "\n",
    "executor4 = client.ScanflowExecutor(name='detector-batch', \n",
    "                      mainfile='checker.py',\n",
    "                      parameters={'model_name': 'mnist_detector',\n",
    "                                  'input_data': '/workflow/load-data/data/x_inference.npy'},\n",
    "                      base_image='checker')\n",
    "\n",
    "executor5 = client.ScanflowExecutor(name='pick-data', \n",
    "                      mainfile='pick-data.py',\n",
    "                      parameters={'e_inference': '/workflow/detector-batch/E_inference.csv',\n",
    "                                  'x_inference_artifact': '/workflow/load-data/data/x_inference.npy',\n",
    "                                  'y_inference_artifact': '/workflow/load-data/data/y_inference.npy'}, \n",
    "                      base_image='checker')\n",
    "\n",
    "dependency2 = client.ScanflowDependency(dependee='load-data',\n",
    "                                    depender='detector-batch')\n",
    "\n",
    "dependency3 = client.ScanflowDependency(dependee='detector-batch',\n",
    "                                    depender='pick-data')\n",
    "\n",
    "##workflow2\n",
    "## -- load-predicted-data\n",
    "##       -- detector-batch\n",
    "##          -- pick-data\n",
    "workflow2 = client.ScanflowWorkflow(name='detector-inference', \n",
    "                     executors=[executor3, executor4, executor5],\n",
    "                     dependencies=[dependency2, dependency3],\n",
    "                     output_dir = \"/workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Develop scanflow agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracker(monitor)\n",
    "trigger = client.ScanflowAgentSensor_IntervalTrigger(hours=1)\n",
    "sensor = client.ScanflowAgentSensor(name='count_number_of_predictions',\n",
    "                                    isCustom=True,\n",
    "                                    func_name='count_number_of_predictions',\n",
    "                                    trigger=trigger)\n",
    "tracker = client.ScanflowAgent(name='tracker',\n",
    "                              template='monitor',\n",
    "                              sensors=[sensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checker(analyzer)\n",
    "# The frequency to retain the model is always in days. for testing we set 1 hour\n",
    "# trigger = client.ScanflowAgentSensor_IntervalTrigger(day=1)\n",
    "trigger = client.ScanflowAgentSensor_IntervalTrigger(hours=1)\n",
    "sensor = client.ScanflowAgentSensor(name='count_number_of_newdata',\n",
    "                                    isCustom=True,\n",
    "                                    func_name='count_number_of_newdata',\n",
    "                                    trigger=trigger)\n",
    "checker = client.ScanflowAgent(name='checker',\n",
    "                              template='analyzer',\n",
    "                              sensors=[sensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#planner\n",
    "# The frequency to change the model is always in days. for testing we set 1 hour\n",
    "# trigger = client.ScanflowAgentSensor_IntervalTrigger(day=1)\n",
    "trigger = client.ScanflowAgentSensor_IntervalTrigger(hours=1)\n",
    "sensor = client.ScanflowAgentSensor(name='check_model_accuracy',\n",
    "                                    isCustom=True,\n",
    "                                    func_name='check_model_accuracy',\n",
    "                                    trigger=trigger)\n",
    "planner = client.ScanflowAgent(name='planner',\n",
    "                              template='planner',\n",
    "                              sensors=[sensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#executor\n",
    "executor = client.ScanflowAgent(name='executor',\n",
    "                              template='executor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Define scanflow application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = client.ScanflowApplication(app_name = app_name,\n",
    "                                 app_dir = app_dir,\n",
    "                                 team_name = team_name,\n",
    "                                 workflows=[workflow1, workflow2],\n",
    "                                 agents=[tracker, checker, planner, executor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic = app.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "### Step3: Build scanflow application (local)\n",
    "   \n",
    "  1. build images for Executor -> save to image registry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-May-21 17:42:20 -  INFO - Building image 172.30.0.49:5000/tracker-agent\n",
      "27-May-21 17:42:20 -  INFO - [+] Image [172.30.0.49:5000/tracker-agent] not found in repository. Building a new one.\n",
      "27-May-21 17:42:20 -  INFO - sensor configuration registered:{\"count_number_of_predictions\": {\"name\": \"count_number_of_predictions\", \"func\": \"scanflow.agent.template.monitor.custom_sensors.count_number_of_predictions\", \"trigger\": {\"type\": \"interval\", \"weeks\": 0, \"days\": 0, \"hours\": 1, \"minutes\": 0, \"seconds\": 0, \"start_date\": null, \"end_date\": null, \"timezone\": null, \"jitter\": null}}}\n",
      "27-May-21 17:42:20 -  INFO - tracker 's Dockerfile \n",
      "FROM 172.30.0.49:5000/scanflow-agent\n",
      "\n",
      "ENV AGENT_NAME tracker\n",
      "ENV AGENT_TYPE monitor\n",
      "\n",
      "RUN mkdir /agent\n",
      "\n",
      "COPY tracker /agent\n",
      "\n",
      "ENV sensors '{\"count_number_of_predictions\": {\"name\": \"count_number_of_predictions\", \"func\": \"scanflow.agent.template.monitor.custom_sensors.count_number_of_predictions\", \"trigger\": {\"type\": \"interval\", \"weeks\": 0, \"days\": 0, \"hours\": 1, \"minutes\": 0, \"seconds\": 0, \"start_date\": null, \"end_date\": null, \"timezone\": null, \"jitter\": null}}}' \n",
      "\n",
      "CMD [ \"cp /agent/* /scanflow/scanflow/scanflow/agent/template/monitor && uvicorn main:agent --reload --host 0.0.0.0 --port 8080\" ]\n",
      "\n",
      "27-May-21 17:42:20 -  INFO - [+] Dockerfile: [Dockerfile_scanflow_agent] was created successfully.\n",
      "27-May-21 17:42:20 -  INFO - dockerfile for using /gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer/agents/tracker/Dockerfile_scanflow_agent from /gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer/agents\n",
      "27-May-21 17:42:21 -  INFO - [+] Image [tracker] was built successfully. image_tag ['172.30.0.49:5000/tracker-agent:latest']\n",
      "27-May-21 17:42:21 -  INFO - [+] Image [tracker] was pushed to registry successfully.\n",
      "27-May-21 17:42:21 -  INFO - Building image 172.30.0.49:5000/checker-agent\n",
      "27-May-21 17:42:21 -  INFO - [+] Image [172.30.0.49:5000/checker-agent] not found in repository. Building a new one.\n",
      "27-May-21 17:42:21 -  INFO - sensor configuration registered:{\"count_number_of_newdata\": {\"name\": \"count_number_of_newdata\", \"func\": \"scanflow.agent.template.analyzer.custom_sensors.count_number_of_newdata\", \"trigger\": {\"type\": \"interval\", \"weeks\": 0, \"days\": 0, \"hours\": 1, \"minutes\": 0, \"seconds\": 0, \"start_date\": null, \"end_date\": null, \"timezone\": null, \"jitter\": null}}}\n",
      "27-May-21 17:42:21 -  INFO - checker 's Dockerfile \n",
      "FROM 172.30.0.49:5000/scanflow-agent\n",
      "\n",
      "ENV AGENT_NAME checker\n",
      "ENV AGENT_TYPE analyzer\n",
      "\n",
      "RUN mkdir /agent\n",
      "\n",
      "COPY checker /agent\n",
      "\n",
      "ENV sensors '{\"count_number_of_newdata\": {\"name\": \"count_number_of_newdata\", \"func\": \"scanflow.agent.template.analyzer.custom_sensors.count_number_of_newdata\", \"trigger\": {\"type\": \"interval\", \"weeks\": 0, \"days\": 0, \"hours\": 1, \"minutes\": 0, \"seconds\": 0, \"start_date\": null, \"end_date\": null, \"timezone\": null, \"jitter\": null}}}' \n",
      "\n",
      "CMD [ \"cp /agent/* /scanflow/scanflow/scanflow/agent/template/analyzer && uvicorn main:agent --reload --host 0.0.0.0 --port 8080\" ]\n",
      "\n",
      "27-May-21 17:42:21 -  INFO - [+] Dockerfile: [Dockerfile_scanflow_agent] was created successfully.\n",
      "27-May-21 17:42:21 -  INFO - dockerfile for using /gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer/agents/checker/Dockerfile_scanflow_agent from /gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer/agents\n",
      "27-May-21 17:42:21 -  INFO - [+] Image [checker] was built successfully. image_tag ['172.30.0.49:5000/checker-agent:latest']\n",
      "27-May-21 17:42:21 -  INFO - [+] Image [checker] was pushed to registry successfully.\n",
      "27-May-21 17:42:21 -  INFO - Building image 172.30.0.49:5000/planner-agent\n",
      "27-May-21 17:42:21 -  INFO - [+] Image [172.30.0.49:5000/planner-agent] not found in repository. Building a new one.\n",
      "27-May-21 17:42:21 -  INFO - sensor configuration registered:{\"check_model_accuracy\": {\"name\": \"check_model_accuracy\", \"func\": \"scanflow.agent.template.planner.custom_sensors.check_model_accuracy\", \"trigger\": {\"type\": \"interval\", \"weeks\": 0, \"days\": 0, \"hours\": 1, \"minutes\": 0, \"seconds\": 0, \"start_date\": null, \"end_date\": null, \"timezone\": null, \"jitter\": null}}}\n",
      "27-May-21 17:42:21 -  INFO - planner 's Dockerfile \n",
      "FROM 172.30.0.49:5000/scanflow-agent\n",
      "\n",
      "ENV AGENT_NAME planner\n",
      "ENV AGENT_TYPE planner\n",
      "\n",
      "RUN mkdir /agent\n",
      "\n",
      "COPY planner /agent\n",
      "\n",
      "ENV sensors '{\"check_model_accuracy\": {\"name\": \"check_model_accuracy\", \"func\": \"scanflow.agent.template.planner.custom_sensors.check_model_accuracy\", \"trigger\": {\"type\": \"interval\", \"weeks\": 0, \"days\": 0, \"hours\": 1, \"minutes\": 0, \"seconds\": 0, \"start_date\": null, \"end_date\": null, \"timezone\": null, \"jitter\": null}}}' \n",
      "\n",
      "CMD [ \"cp /agent/* /scanflow/scanflow/scanflow/agent/template/planner && uvicorn main:agent --reload --host 0.0.0.0 --port 8080\" ]\n",
      "\n",
      "27-May-21 17:42:21 -  INFO - [+] Dockerfile: [Dockerfile_scanflow_agent] was created successfully.\n",
      "27-May-21 17:42:21 -  INFO - dockerfile for using /gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer/agents/planner/Dockerfile_scanflow_agent from /gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer/agents\n",
      "27-May-21 17:42:21 -  INFO - [+] Image [planner] was built successfully. image_tag ['172.30.0.49:5000/planner-agent:latest']\n",
      "27-May-21 17:42:22 -  INFO - [+] Image [planner] was pushed to registry successfully.\n",
      "27-May-21 17:42:22 -  INFO - Building image 172.30.0.49:5000/executor-agent\n",
      "27-May-21 17:42:22 -  INFO - [+] Image [172.30.0.49:5000/executor-agent] not found in repository. Building a new one.\n",
      "27-May-21 17:42:22 -  INFO - executor 's Dockerfile \n",
      "FROM 172.30.0.49:5000/scanflow-agent\n",
      "\n",
      "ENV AGENT_NAME executor\n",
      "ENV AGENT_TYPE executor\n",
      "\n",
      "RUN mkdir /agent\n",
      "\n",
      "CMD [ \"cp /agent/* /scanflow/scanflow/scanflow/agent/template/executor && uvicorn main:agent --reload --host 0.0.0.0 --port 8080\" ]\n",
      "\n",
      "27-May-21 17:42:22 -  INFO - [+] Dockerfile: [Dockerfile_scanflow_agent] was created successfully.\n",
      "27-May-21 17:42:22 -  INFO - dockerfile for using /gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer/agents/executor/Dockerfile_scanflow_agent from /gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer/agents\n",
      "27-May-21 17:42:22 -  INFO - [+] Image [executor] was built successfully. image_tag ['172.30.0.49:5000/executor-agent:latest']\n",
      "27-May-21 17:42:22 -  INFO - [+] Image [executor] was pushed to registry successfully.\n",
      "27-May-21 17:42:22 -  INFO - Building image 172.30.0.49:5000/load-data\n",
      "27-May-21 17:42:22 -  INFO - Building image 172.30.0.49:5000/predictor-batch\n",
      "27-May-21 17:42:22 -  INFO - Building image 172.30.0.49:5000/load-data\n",
      "27-May-21 17:42:22 -  INFO - Building image 172.30.0.49:5000/detector-batch\n",
      "27-May-21 17:42:22 -  INFO - Building image 172.30.0.49:5000/pick-data\n"
     ]
    }
   ],
   "source": [
    "build_app = client.build_ScanflowApplication(app = app, trackerPort=46669)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-May-21 17:42:30 -  INFO - Scanflowagent-tracker: {'name': 'tracker', 'template': 'monitor', 'sensors': [{'name': 'count_number_of_predictions', 'isCustom': True, 'func_name': 'count_number_of_predictions', 'trigger': {'weeks': 0, 'days': 0, 'hours': 1, 'minutes': 0, 'seconds': 0, 'start_date': None, 'end_date': None, 'timezone': None, 'jitter': None}, 'args': None, 'kwargs': None, 'next_run_time': None}], 'dockerfile': None, 'image': '172.30.0.49:5000/tracker-agent:latest'}\n",
      "27-May-21 17:42:30 -  INFO - Scanflowagent-checker: {'name': 'checker', 'template': 'analyzer', 'sensors': [{'name': 'count_number_of_newdata', 'isCustom': True, 'func_name': 'count_number_of_newdata', 'trigger': {'weeks': 0, 'days': 0, 'hours': 1, 'minutes': 0, 'seconds': 0, 'start_date': None, 'end_date': None, 'timezone': None, 'jitter': None}, 'args': None, 'kwargs': None, 'next_run_time': None}], 'dockerfile': None, 'image': '172.30.0.49:5000/checker-agent:latest'}\n",
      "27-May-21 17:42:30 -  INFO - Scanflowagent-planner: {'name': 'planner', 'template': 'planner', 'sensors': [{'name': 'check_model_accuracy', 'isCustom': True, 'func_name': 'check_model_accuracy', 'trigger': {'weeks': 0, 'days': 0, 'hours': 1, 'minutes': 0, 'seconds': 0, 'start_date': None, 'end_date': None, 'timezone': None, 'jitter': None}, 'args': None, 'kwargs': None, 'next_run_time': None}], 'dockerfile': None, 'image': '172.30.0.49:5000/planner-agent:latest'}\n",
      "27-May-21 17:42:30 -  INFO - Scanflowagent-executor: {'name': 'executor', 'template': 'executor', 'sensors': None, 'dockerfile': None, 'image': '172.30.0.49:5000/executor-agent:latest'}\n",
      "27-May-21 17:42:30 -  INFO - Scanflowapp: {'app_name': 'mnist', 'app_dir': '/gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer', 'team_name': 'dataengineer', 'workflows': [{'name': 'batch-inference', 'executors': [{'name': 'load-data', 'mainfile': 'loaddata.py', 'parameters': {'app_name': 'mnist', 'team_name': 'data'}, 'requirements': None, 'dockerfile': None, 'base_image': None, 'env': None, 'image': '172.30.0.49:5000/load-data:latest'}, {'name': 'predictor-batch', 'mainfile': 'predictor.py', 'parameters': {'model_name': 'mnist_cnn', 'input_data': '/workflow/load-data/mnist/data/mnist_sample/test_images.npy'}, 'requirements': None, 'dockerfile': None, 'base_image': 'modeling-cnn1', 'env': None, 'image': '172.30.0.49:5000/predictor-batch:latest'}], 'dependencies': [{'depender': 'predictor-batch', 'dependee': 'load-data', 'priority': 0}], 'output_dir': '/workflow'}, {'name': 'detector-inference', 'executors': [{'name': 'load-data', 'mainfile': 'loaddata.py', 'parameters': {'experiment_name': 'checker', 'run_id': '', 'path': 'data'}, 'requirements': None, 'dockerfile': None, 'base_image': None, 'env': None, 'image': '172.30.0.49:5000/load-data:latest'}, {'name': 'detector-batch', 'mainfile': 'checker.py', 'parameters': {'model_name': 'mnist_detector', 'input_data': '/workflow/load-data/data/x_inference.npy'}, 'requirements': None, 'dockerfile': None, 'base_image': 'checker', 'env': None, 'image': '172.30.0.49:5000/detector-batch:latest'}, {'name': 'pick-data', 'mainfile': 'pick-data.py', 'parameters': {'e_inference': '/workflow/detector-batch/E_inference.csv', 'x_inference_artifact': '/workflow/load-data/data/x_inference.npy', 'y_inference_artifact': '/workflow/load-data/data/y_inference.npy'}, 'requirements': None, 'dockerfile': None, 'base_image': 'checker', 'env': None, 'image': '172.30.0.49:5000/pick-data:latest'}], 'dependencies': [{'depender': 'detector-batch', 'dependee': 'load-data', 'priority': 0}, {'depender': 'pick-data', 'dependee': 'detector-batch', 'priority': 0}], 'output_dir': '/workflow'}], 'agents': [{'name': 'tracker', 'template': 'monitor', 'sensors': [{'name': 'count_number_of_predictions', 'isCustom': True, 'func_name': 'count_number_of_predictions', 'trigger': {'weeks': 0, 'days': 0, 'hours': 1, 'minutes': 0, 'seconds': 0, 'start_date': None, 'end_date': None, 'timezone': None, 'jitter': None}, 'args': None, 'kwargs': None, 'next_run_time': None}], 'dockerfile': None, 'image': '172.30.0.49:5000/tracker-agent:latest'}, {'name': 'checker', 'template': 'analyzer', 'sensors': [{'name': 'count_number_of_newdata', 'isCustom': True, 'func_name': 'count_number_of_newdata', 'trigger': {'weeks': 0, 'days': 0, 'hours': 1, 'minutes': 0, 'seconds': 0, 'start_date': None, 'end_date': None, 'timezone': None, 'jitter': None}, 'args': None, 'kwargs': None, 'next_run_time': None}], 'dockerfile': None, 'image': '172.30.0.49:5000/checker-agent:latest'}, {'name': 'planner', 'template': 'planner', 'sensors': [{'name': 'check_model_accuracy', 'isCustom': True, 'func_name': 'check_model_accuracy', 'trigger': {'weeks': 0, 'days': 0, 'hours': 1, 'minutes': 0, 'seconds': 0, 'start_date': None, 'end_date': None, 'timezone': None, 'jitter': None}, 'args': None, 'kwargs': None, 'next_run_time': None}], 'dockerfile': None, 'image': '172.30.0.49:5000/planner-agent:latest'}, {'name': 'executor', 'template': 'executor', 'sensors': None, 'dockerfile': None, 'image': '172.30.0.49:5000/executor-agent:latest'}], 'tracker': {'image': '172.30.0.49:5000/scanflow-tracker', 'nodePort': 46669}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'app_name': 'mnist',\n",
       " 'app_dir': '/gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer',\n",
       " 'team_name': 'dataengineer',\n",
       " 'workflows': [{'name': 'batch-inference',\n",
       "   'executors': [{'name': 'load-data',\n",
       "     'mainfile': 'loaddata.py',\n",
       "     'parameters': {'app_name': 'mnist', 'team_name': 'data'},\n",
       "     'requirements': None,\n",
       "     'dockerfile': None,\n",
       "     'base_image': None,\n",
       "     'env': None,\n",
       "     'image': '172.30.0.49:5000/load-data:latest'},\n",
       "    {'name': 'predictor-batch',\n",
       "     'mainfile': 'predictor.py',\n",
       "     'parameters': {'model_name': 'mnist_cnn',\n",
       "      'input_data': '/workflow/load-data/mnist/data/mnist_sample/test_images.npy'},\n",
       "     'requirements': None,\n",
       "     'dockerfile': None,\n",
       "     'base_image': 'modeling-cnn1',\n",
       "     'env': None,\n",
       "     'image': '172.30.0.49:5000/predictor-batch:latest'}],\n",
       "   'dependencies': [{'depender': 'predictor-batch',\n",
       "     'dependee': 'load-data',\n",
       "     'priority': 0}],\n",
       "   'output_dir': '/workflow'},\n",
       "  {'name': 'detector-inference',\n",
       "   'executors': [{'name': 'load-data',\n",
       "     'mainfile': 'loaddata.py',\n",
       "     'parameters': {'experiment_name': 'checker',\n",
       "      'run_id': '',\n",
       "      'path': 'data'},\n",
       "     'requirements': None,\n",
       "     'dockerfile': None,\n",
       "     'base_image': None,\n",
       "     'env': None,\n",
       "     'image': '172.30.0.49:5000/load-data:latest'},\n",
       "    {'name': 'detector-batch',\n",
       "     'mainfile': 'checker.py',\n",
       "     'parameters': {'model_name': 'mnist_detector',\n",
       "      'input_data': '/workflow/load-data/data/x_inference.npy'},\n",
       "     'requirements': None,\n",
       "     'dockerfile': None,\n",
       "     'base_image': 'checker',\n",
       "     'env': None,\n",
       "     'image': '172.30.0.49:5000/detector-batch:latest'},\n",
       "    {'name': 'pick-data',\n",
       "     'mainfile': 'pick-data.py',\n",
       "     'parameters': {'e_inference': '/workflow/detector-batch/E_inference.csv',\n",
       "      'x_inference_artifact': '/workflow/load-data/data/x_inference.npy',\n",
       "      'y_inference_artifact': '/workflow/load-data/data/y_inference.npy'},\n",
       "     'requirements': None,\n",
       "     'dockerfile': None,\n",
       "     'base_image': 'checker',\n",
       "     'env': None,\n",
       "     'image': '172.30.0.49:5000/pick-data:latest'}],\n",
       "   'dependencies': [{'depender': 'detector-batch',\n",
       "     'dependee': 'load-data',\n",
       "     'priority': 0},\n",
       "    {'depender': 'pick-data', 'dependee': 'detector-batch', 'priority': 0}],\n",
       "   'output_dir': '/workflow'}],\n",
       " 'agents': [{'name': 'tracker',\n",
       "   'template': 'monitor',\n",
       "   'sensors': [{'name': 'count_number_of_predictions',\n",
       "     'isCustom': True,\n",
       "     'func_name': 'count_number_of_predictions',\n",
       "     'trigger': {'weeks': 0,\n",
       "      'days': 0,\n",
       "      'hours': 1,\n",
       "      'minutes': 0,\n",
       "      'seconds': 0,\n",
       "      'start_date': None,\n",
       "      'end_date': None,\n",
       "      'timezone': None,\n",
       "      'jitter': None},\n",
       "     'args': None,\n",
       "     'kwargs': None,\n",
       "     'next_run_time': None}],\n",
       "   'dockerfile': None,\n",
       "   'image': '172.30.0.49:5000/tracker-agent:latest'},\n",
       "  {'name': 'checker',\n",
       "   'template': 'analyzer',\n",
       "   'sensors': [{'name': 'count_number_of_newdata',\n",
       "     'isCustom': True,\n",
       "     'func_name': 'count_number_of_newdata',\n",
       "     'trigger': {'weeks': 0,\n",
       "      'days': 0,\n",
       "      'hours': 1,\n",
       "      'minutes': 0,\n",
       "      'seconds': 0,\n",
       "      'start_date': None,\n",
       "      'end_date': None,\n",
       "      'timezone': None,\n",
       "      'jitter': None},\n",
       "     'args': None,\n",
       "     'kwargs': None,\n",
       "     'next_run_time': None}],\n",
       "   'dockerfile': None,\n",
       "   'image': '172.30.0.49:5000/checker-agent:latest'},\n",
       "  {'name': 'planner',\n",
       "   'template': 'planner',\n",
       "   'sensors': [{'name': 'check_model_accuracy',\n",
       "     'isCustom': True,\n",
       "     'func_name': 'check_model_accuracy',\n",
       "     'trigger': {'weeks': 0,\n",
       "      'days': 0,\n",
       "      'hours': 1,\n",
       "      'minutes': 0,\n",
       "      'seconds': 0,\n",
       "      'start_date': None,\n",
       "      'end_date': None,\n",
       "      'timezone': None,\n",
       "      'jitter': None},\n",
       "     'args': None,\n",
       "     'kwargs': None,\n",
       "     'next_run_time': None}],\n",
       "   'dockerfile': None,\n",
       "   'image': '172.30.0.49:5000/planner-agent:latest'},\n",
       "  {'name': 'executor',\n",
       "   'template': 'executor',\n",
       "   'sensors': None,\n",
       "   'dockerfile': None,\n",
       "   'image': '172.30.0.49:5000/executor-agent:latest'}],\n",
       " 'tracker': {'image': '172.30.0.49:5000/scanflow-tracker', 'nodePort': 46669}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_app.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4: Deploy scanflow environment (local/incluster)\n",
    "  \n",
    "  1. Create k8s environment\n",
    "        - create namespace\n",
    "        - create RBAC, secret, configmap, PV, PVC\n",
    "        \n",
    "  2. Deploy scanflow-local-tracker (deployment, service)\n",
    " \n",
    "  3. Deploy scanflow-agents\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-May-21 17:42:31 -  INFO - loading kubernetes configuration from /gpfs/bsc_home/xpliu/.kube/config\n",
      "27-May-21 17:42:31 -  INFO - found local kubernetes configuration\n",
      "27-May-21 17:42:31 -  INFO - seldon backend is not ready!\n"
     ]
    }
   ],
   "source": [
    "deployerClient = ScanflowDeployerClient(user_type=\"local\",\n",
    "                                        deployer=\"seldon\",\n",
    "                                        k8s_config_file=\"/gpfs/bsc_home/xpliu/.kube/config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-May-21 17:42:32 -  INFO - [++]Creating env\n",
      "27-May-21 17:42:32 -  INFO - [++]Creating namespace \"scanflow-mnist-dataengineer\"\n",
      "27-May-21 17:42:32 -  INFO - create_namespace true\n",
      "27-May-21 17:42:32 -  INFO - [++]Creating Role for 'default service account'\n",
      "27-May-21 17:42:32 -  INFO - create_rolebinding info\n",
      "27-May-21 17:42:32 -  INFO - [++]Creating s3 secret {'AWS_ACCESS_KEY_ID': 'admin', 'AWS_SECRET_ACCESS_KEY': 'admin123', 'MLFLOW_S3_ENDPOINT_URL': 'http://minio.minio-system.svc.cluster.local:9000'}\n",
      "27-May-21 17:42:32 -  INFO - create_secret true\n",
      "27-May-21 17:42:32 -  INFO - [++]Creating tracker configmap {'TRACKER_STORAGE': 'postgresql://scanflow:scanflow123@postgresql-service.postgresql.svc.cluster.local/scanflow-mnist-dataengineer', 'TRACKER_ARTIFACT': 's3://scanflow/scanflow-mnist-dataengineer'}\n",
      "27-May-21 17:42:32 -  INFO - create_configmap true\n",
      "27-May-21 17:42:32 -  INFO - [++]Creating client configmap {'SCANFLOW_TRACKER_URI': 'http://scanflow-tracker-service.scanflow-system.svc.cluster.local', 'SCANFLOW_SERVER_URI': 'http://scanflow-server-service.scanflow-system.svc.cluster.local', 'SCANFLOW_TRACKER_LOCAL_URI': 'http://scanflow-tracker.scanflow-mnist-dataengineer.svc.cluster.local'}\n",
      "27-May-21 17:42:32 -  INFO - create_configmap true\n",
      "27-May-21 17:42:32 -  INFO - [+] Starting local tracker: [scanflow-tracker].\n",
      "27-May-21 17:42:32 -  INFO - create_deployment true \n",
      "27-May-21 17:42:32 -  INFO - [+] Created tracker Deployment True\n",
      "27-May-21 17:42:32 -  INFO - create_service true\n",
      "27-May-21 17:42:32 -  INFO - [+] Created tracker Service True\n",
      "27-May-21 17:42:32 -  INFO - [TEMPO: Because we dont have scanflow pip install now, we need to mount scanflow]\n",
      "27-May-21 17:42:32 -  INFO - create_pv true\n",
      "27-May-21 17:42:32 -  INFO - create_pvc true\n",
      "27-May-21 17:42:32 -  INFO - create_deployment true \n",
      "27-May-21 17:42:32 -  INFO - [+] Created tracker Deployment True\n",
      "27-May-21 17:42:32 -  INFO - create_service true\n",
      "27-May-21 17:42:32 -  INFO - [+] Created tracker Service True\n",
      "27-May-21 17:42:32 -  INFO - create_deployment true \n",
      "27-May-21 17:42:32 -  INFO - [+] Created checker Deployment True\n",
      "27-May-21 17:42:32 -  INFO - create_service true\n",
      "27-May-21 17:42:32 -  INFO - [+] Created checker Service True\n",
      "27-May-21 17:42:32 -  INFO - create_deployment true \n",
      "27-May-21 17:42:32 -  INFO - [+] Created planner Deployment True\n",
      "27-May-21 17:42:32 -  INFO - create_service true\n",
      "27-May-21 17:42:32 -  INFO - [+] Created planner Service True\n",
      "27-May-21 17:42:32 -  INFO - create_deployment true \n",
      "27-May-21 17:42:32 -  INFO - [+] Created executor Deployment True\n",
      "27-May-21 17:42:32 -  INFO - create_service true\n",
      "27-May-21 17:42:32 -  INFO - [+] Created executor Service True\n"
     ]
    }
   ],
   "source": [
    "await deployerClient.create_environment(app=build_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5: download prepared production mnist model\n",
    "   - download mnist-checker model (e.g., mnist_detector)\n",
    "   - download mnist model (e.g., mnist_cnn)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackerClient = ScanflowTrackerClient(scanflow_tracker_local_uri=\"http://172.30.0.50:46669\",\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-May-21 16:50:30 -  INFO - Found credentials in environment variables.\n",
      "25-May-21 16:50:31 -  INFO - mnist--scanflow-model-datascience--{'training_dataset_len': 60000.0, 'accuracy': 0.9}--{}\n",
      "25-May-21 16:50:32 -  INFO - mnist_cnn exists\n",
      "2021/05/25 16:50:32 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: mnist_cnn, version 3\n"
     ]
    }
   ],
   "source": [
    "trackerClient.download_app_model(model_name=\"mnist_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-May-21 15:02:05 -  INFO - mnist--scanflow-model-datascience--{'history_val_loss': 0.08708706498146057, 'val_loss': 0.08708706498146057}--{'THRESHOLD_HIGH': '0.4934456065297127', 'THRESHOLD_LOW': '0.1665979415178299'}\n",
      "25-May-21 15:02:06 -  INFO - mnist_detector exists\n",
      "2021/05/25 15:02:06 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: mnist_detector, version 2\n"
     ]
    }
   ],
   "source": [
    "trackerClient.download_app_model(model_name=\"mnist_detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6: Submit the metadata and artifacts to the central Scanflow-tracker\n",
    "\n",
    "  #### 6.1. Submit scanflowapp metadata\n",
    "  ```bash\n",
    "   mnist\n",
    "    - dataengineer\n",
    "     - workflows\n",
    "        - batch-inference.json\n",
    "        - detector-inference.json\n",
    "     - mnist.json\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackerClient = ScanflowTrackerClient(scanflow_tracker_local_uri=\"http://172.30.0.50:46669\",\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-May-21 16:01:31 -  INFO - Connecting tracking server uri: http://172.30.0.50:46667\n",
      "25-May-21 16:01:32 -  INFO - save app to artifact uri: s3://scanflow/1/f9609387d935405e8d0b0725d76d79fd/artifacts\n",
      "25-May-21 16:01:32 -  INFO - Scanflowapp: {'app_name': 'mnist', 'app_dir': '/gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer', 'team_name': 'dataengineer', 'workflows': [{'name': 'batch-inference', 'executors': [{'name': 'load-data', 'mainfile': 'loaddata.py', 'parameters': {'app_name': 'mnist', 'team_name': 'data'}, 'requirements': None, 'dockerfile': None, 'base_image': None, 'env': None, 'image': '172.30.0.49:5000/load-data:latest'}, {'name': 'predictor-batch', 'mainfile': 'predictor.py', 'parameters': {'model_name': 'mnist_cnn', 'input_data': '/workflow/load-data/mnist/data/mnist_sample/test_images.npy'}, 'requirements': None, 'dockerfile': None, 'base_image': 'modeling-cnn1', 'env': None, 'image': '172.30.0.49:5000/predictor-batch:latest'}], 'dependencies': [{'depender': 'predictor-batch', 'dependee': 'load-data', 'priority': 0}], 'output_dir': '/workflow'}, {'name': 'detector-inference', 'executors': [{'name': 'load-data', 'mainfile': 'loaddata.py', 'parameters': {'experiment_name': 'checker', 'run_id': '', 'path': 'data'}, 'requirements': None, 'dockerfile': None, 'base_image': None, 'env': None, 'image': '172.30.0.49:5000/load-data:latest'}, {'name': 'detector-batch', 'mainfile': 'checker.py', 'parameters': {'model_name': 'mnist_detector', 'input_data': '/workflow/load-data/data/x_inference.npy'}, 'requirements': None, 'dockerfile': None, 'base_image': 'checker', 'env': None, 'image': '172.30.0.49:5000/detector-batch:latest'}, {'name': 'pick-data', 'mainfile': 'pick-data.py', 'parameters': {'e_inference': '/workflow/detector-batch/E_inference.csv', 'x_inference_artifact': '/workflow/load-data/data/x_inference.npy', 'y_inference_artifact': '/workflow/load-data/data/y_inference.npy'}, 'requirements': None, 'dockerfile': None, 'base_image': 'checker', 'env': None, 'image': '172.30.0.49:5000/pick-data:latest'}], 'dependencies': [{'depender': 'detector-batch', 'dependee': 'load-data', 'priority': 0}, {'depender': 'pick-data', 'dependee': 'detector-batch', 'priority': 0}], 'output_dir': '/workflow'}], 'agents': None, 'tracker': {'image': '172.30.0.49:5000/scanflow-tracker', 'nodePort': 46669}}\n",
      "25-May-21 16:01:32 -  INFO - Found credentials in environment variables.\n"
     ]
    }
   ],
   "source": [
    "trackerClient.save_app_meta(build_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Submit artifacts\n",
    "\n",
    "  ```bash\n",
    "mnist\n",
    "    - workflows\n",
    "       - load_data\n",
    "         - loaddata.py\n",
    "       - predictor-batch\n",
    "         - predictor.py\n",
    "       - detector-batch\n",
    "         - checker.py\n",
    "       - pick-data\n",
    "         - pick-data.py\n",
    "    - agents\n",
    "       - tracker\n",
    "       - checker\n",
    "       - improver\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-May-21 13:38:16 -  INFO - Connecting tracking server uri: http://172.30.0.50:46667\n",
      "25-May-21 13:38:16 -  INFO - save app in /gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mnist/dataengineer to artifact uri: s3://scanflow/1/4eeb989ac7164e0798f45c0fc4b0de9a/artifacts\n"
     ]
    }
   ],
   "source": [
    "trackerClient.save_app_artifacts(app_name=app_name, \n",
    "                                team_name=team_name, \n",
    "                                app_dir=app_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step7: ****[Inference]****\n",
    "\n",
    "#### 7.1. Batch Inference\n",
    "\n",
    "Batch worklflow(workflow[0]:batch-inference) is defined by dataengineer, client could use it by changing the parameters.\n",
    "\n",
    "Below simulate the client makes predictions by using default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-May-21 15:58:22 -  INFO - [+] output dir /workflow\n",
      "25-May-21 15:58:22 -  INFO - [+] Create batch-inference output PV\n",
      "25-May-21 15:58:22 -  INFO - create_pv true\n",
      "25-May-21 15:58:22 -  INFO - [+] Create batch-inference output PVC\n",
      "25-May-21 15:58:22 -  INFO - create_pvc true\n",
      "25-May-21 15:58:22 -  INFO - output dir created\n",
      "25-May-21 15:58:22 -  INFO - env for executor {'AWS_ACCESS_KEY_ID': 'admin', 'AWS_SECRET_ACCESS_KEY': 'admin123', 'MLFLOW_S3_ENDPOINT_URL': 'http://minio.minio-system.svc.cluster.local:9000', 'SCANFLOW_TRACKER_URI': 'http://scanflow-tracker-service.scanflow-system.svc.cluster.local', 'SCANFLOW_SERVER_URI': 'http://scanflow-server-service.scanflow-system.svc.cluster.local', 'SCANFLOW_TRACKER_LOCAL_URI': 'http://scanflow-tracker.scanflow-mnist-dataengineer.svc.cluster.local'}\n",
      "25-May-21 15:58:22 -  INFO - [+] Building workflow: [batch-inference:load-data].\n",
      "25-May-21 15:58:22 -  INFO - ['--app_name', 'mnist', '--team_name', 'data']\n",
      "25-May-21 15:58:22 -  INFO - [+] Building workflow: [batch-inference:predictor-batch].\n",
      "25-May-21 15:58:22 -  INFO - ['--model_name', 'mnist_cnn', '--input_data', '/workflow/load-data/mnist/data/mnist_sample/test_images.npy']\n",
      "25-May-21 15:58:22 -  INFO - [+] Building workflow: [batch-inference- dependencies]\n",
      "25-May-21 15:58:22 -  INFO - [+] Building workflow: [batch-inference- dag]\n",
      "25-May-21 15:58:22 -  INFO - Found local kubernetes config. Initialized with kube_config.\n",
      "25-May-21 15:58:22 -  INFO - Checking workflow name/generatedName batch-inference\n",
      "25-May-21 15:58:22 -  INFO - Submitting workflow to Argo\n",
      "25-May-21 15:58:22 -  INFO - Workflow batch-inference has been submitted in \"scanflow-mnist-dataengineer\" namespace!\n",
      "25-May-21 15:58:22 -  INFO - [+++] Workflow: [batch-inference] has been submitted to argo {'apiVersion': 'argoproj.io/v1alpha1', 'kind': 'Workflow', 'metadata': {'creationTimestamp': '2021-05-25T13:58:22Z', 'generation': 1, 'managedFields': [{'apiVersion': 'argoproj.io/v1alpha1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:spec': {'.': {}, 'f:activeDeadlineSeconds': {}, 'f:entrypoint': {}, 'f:templates': {}, 'f:ttlSecondsAfterFinished': {}, 'f:volumes': {}}}, 'manager': 'OpenAPI-Generator', 'operation': 'Update', 'time': '2021-05-25T13:58:22Z'}], 'name': 'batch-inference', 'namespace': 'scanflow-mnist-dataengineer', 'resourceVersion': '44766998', 'selfLink': '/apis/argoproj.io/v1alpha1/namespaces/scanflow-mnist-dataengineer/workflows/batch-inference', 'uid': '73ef5d5e-228b-4993-ae69-332e6b69c3a5'}, 'spec': {'activeDeadlineSeconds': 3600, 'entrypoint': 'batch-inference', 'templates': [{'dag': {'tasks': [{'arguments': {'parameters': [{'name': 'para-load-data-0', 'value': '--app_name'}, {'name': 'para-load-data-1', 'value': 'mnist'}, {'name': 'para-load-data-2', 'value': '--team_name'}, {'name': 'para-load-data-3', 'value': 'data'}]}, 'name': 'load-data', 'template': 'load-data'}, {'arguments': {'parameters': [{'name': 'para-predictor-batch-0', 'value': '--model_name'}, {'name': 'para-predictor-batch-1', 'value': 'mnist_cnn'}, {'name': 'para-predictor-batch-2', 'value': '--input_data'}, {'name': 'para-predictor-batch-3', 'value': '/workflow/load-data/mnist/data/mnist_sample/test_images.npy'}]}, 'dependencies': ['load-data'], 'name': 'predictor-batch', 'template': 'predictor-batch'}]}, 'name': 'batch-inference'}, {'container': {'args': ['{{inputs.parameters.para-load-data-0}}', '{{inputs.parameters.para-load-data-1}}', '{{inputs.parameters.para-load-data-2}}', '{{inputs.parameters.para-load-data-3}}'], 'command': None, 'env': [{'name': 'AWS_ACCESS_KEY_ID', 'value': 'admin'}, {'name': 'AWS_SECRET_ACCESS_KEY', 'value': 'admin123'}, {'name': 'MLFLOW_S3_ENDPOINT_URL', 'value': 'http://minio.minio-system.svc.cluster.local:9000'}, {'name': 'SCANFLOW_TRACKER_URI', 'value': 'http://scanflow-tracker-service.scanflow-system.svc.cluster.local'}, {'name': 'SCANFLOW_SERVER_URI', 'value': 'http://scanflow-server-service.scanflow-system.svc.cluster.local'}, {'name': 'SCANFLOW_TRACKER_LOCAL_URI', 'value': 'http://scanflow-tracker.scanflow-mnist-dataengineer.svc.cluster.local'}], 'image': '172.30.0.49:5000/load-data:latest', 'volumeMounts': [{'mountPath': '/workflow', 'name': 'outputpath'}, {'mountPath': '/scanflow', 'name': 'scanflowpath'}]}, 'inputs': {'parameters': [{'name': 'para-load-data-0'}, {'name': 'para-load-data-1'}, {'name': 'para-load-data-2'}, {'name': 'para-load-data-3'}]}, 'name': 'load-data', 'volumes': []}, {'container': {'args': ['{{inputs.parameters.para-predictor-batch-0}}', '{{inputs.parameters.para-predictor-batch-1}}', '{{inputs.parameters.para-predictor-batch-2}}', '{{inputs.parameters.para-predictor-batch-3}}'], 'command': None, 'env': [{'name': 'AWS_ACCESS_KEY_ID', 'value': 'admin'}, {'name': 'AWS_SECRET_ACCESS_KEY', 'value': 'admin123'}, {'name': 'MLFLOW_S3_ENDPOINT_URL', 'value': 'http://minio.minio-system.svc.cluster.local:9000'}, {'name': 'SCANFLOW_TRACKER_URI', 'value': 'http://scanflow-tracker-service.scanflow-system.svc.cluster.local'}, {'name': 'SCANFLOW_SERVER_URI', 'value': 'http://scanflow-server-service.scanflow-system.svc.cluster.local'}, {'name': 'SCANFLOW_TRACKER_LOCAL_URI', 'value': 'http://scanflow-tracker.scanflow-mnist-dataengineer.svc.cluster.local'}], 'image': '172.30.0.49:5000/predictor-batch:latest', 'volumeMounts': [{'mountPath': '/workflow', 'name': 'outputpath'}, {'mountPath': '/scanflow', 'name': 'scanflowpath'}]}, 'inputs': {'parameters': [{'name': 'para-predictor-batch-0'}, {'name': 'para-predictor-batch-1'}, {'name': 'para-predictor-batch-2'}, {'name': 'para-predictor-batch-3'}]}, 'name': 'predictor-batch', 'volumes': []}], 'ttlSecondsAfterFinished': 5400, 'volumes': [{'name': 'outputpath', 'persistentVolumeClaim': {'claimName': 'batch-inference'}}, {'name': 'scanflowpath', 'persistentVolumeClaim': {'claimName': 'scanflow-scanflow-mnist-dataengineer'}}]}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('apiVersion', 'argoproj.io/v1alpha1'), ('kind', 'Workflow'), ('metadata', {'name': 'batch-inference'}), ('spec', {'entrypoint': 'batch-inference', 'volumes': [OrderedDict([('name', 'outputpath'), ('persistentVolumeClaim', {'claimName': 'batch-inference'})]), OrderedDict([('name', 'scanflowpath'), ('persistentVolumeClaim', {'claimName': 'scanflow-scanflow-mnist-dataengineer'})])], 'templates': [OrderedDict([('name', 'batch-inference'), ('dag', {'tasks': [OrderedDict([('name', 'load-data'), ('template', 'load-data'), ('arguments', OrderedDict([('parameters', [{'name': 'para-load-data-0', 'value': '--app_name'}, {'name': 'para-load-data-1', 'value': 'mnist'}, {'name': 'para-load-data-2', 'value': '--team_name'}, {'name': 'para-load-data-3', 'value': 'data'}])]))]), OrderedDict([('name', 'predictor-batch'), ('dependencies', ['load-data']), ('template', 'predictor-batch'), ('arguments', OrderedDict([('parameters', [{'name': 'para-predictor-batch-0', 'value': '--model_name'}, {'name': 'para-predictor-batch-1', 'value': 'mnist_cnn'}, {'name': 'para-predictor-batch-2', 'value': '--input_data'}, {'name': 'para-predictor-batch-3', 'value': '/workflow/load-data/mnist/data/mnist_sample/test_images.npy'}])]))])]})]), OrderedDict([('name', 'load-data'), ('inputs', OrderedDict([('parameters', [{'name': 'para-load-data-0'}, {'name': 'para-load-data-1'}, {'name': 'para-load-data-2'}, {'name': 'para-load-data-3'}])])), ('container', OrderedDict([('image', '172.30.0.49:5000/load-data:latest'), ('command', None), ('args', ['\"{{inputs.parameters.para-load-data-0}}\"', '\"{{inputs.parameters.para-load-data-1}}\"', '\"{{inputs.parameters.para-load-data-2}}\"', '\"{{inputs.parameters.para-load-data-3}}\"']), ('env', [{'name': 'AWS_ACCESS_KEY_ID', 'value': 'admin'}, {'name': 'AWS_SECRET_ACCESS_KEY', 'value': 'admin123'}, {'name': 'MLFLOW_S3_ENDPOINT_URL', 'value': 'http://minio.minio-system.svc.cluster.local:9000'}, {'name': 'SCANFLOW_TRACKER_URI', 'value': 'http://scanflow-tracker-service.scanflow-system.svc.cluster.local'}, {'name': 'SCANFLOW_SERVER_URI', 'value': 'http://scanflow-server-service.scanflow-system.svc.cluster.local'}, {'name': 'SCANFLOW_TRACKER_LOCAL_URI', 'value': 'http://scanflow-tracker.scanflow-mnist-dataengineer.svc.cluster.local'}]), ('volumeMounts', [OrderedDict([('name', 'outputpath'), ('mountPath', '/workflow')]), OrderedDict([('name', 'scanflowpath'), ('mountPath', '/scanflow')])])])), ('volumes', [])]), OrderedDict([('name', 'predictor-batch'), ('inputs', OrderedDict([('parameters', [{'name': 'para-predictor-batch-0'}, {'name': 'para-predictor-batch-1'}, {'name': 'para-predictor-batch-2'}, {'name': 'para-predictor-batch-3'}])])), ('container', OrderedDict([('image', '172.30.0.49:5000/predictor-batch:latest'), ('command', None), ('args', ['\"{{inputs.parameters.para-predictor-batch-0}}\"', '\"{{inputs.parameters.para-predictor-batch-1}}\"', '\"{{inputs.parameters.para-predictor-batch-2}}\"', '\"{{inputs.parameters.para-predictor-batch-3}}\"']), ('env', [{'name': 'AWS_ACCESS_KEY_ID', 'value': 'admin'}, {'name': 'AWS_SECRET_ACCESS_KEY', 'value': 'admin123'}, {'name': 'MLFLOW_S3_ENDPOINT_URL', 'value': 'http://minio.minio-system.svc.cluster.local:9000'}, {'name': 'SCANFLOW_TRACKER_URI', 'value': 'http://scanflow-tracker-service.scanflow-system.svc.cluster.local'}, {'name': 'SCANFLOW_SERVER_URI', 'value': 'http://scanflow-server-service.scanflow-system.svc.cluster.local'}, {'name': 'SCANFLOW_TRACKER_LOCAL_URI', 'value': 'http://scanflow-tracker.scanflow-mnist-dataengineer.svc.cluster.local'}]), ('volumeMounts', [OrderedDict([('name', 'outputpath'), ('mountPath', '/workflow')]), OrderedDict([('name', 'scanflowpath'), ('mountPath', '/scanflow')])])])), ('volumes', [])])], 'activeDeadlineSeconds': 3600, 'ttlSecondsAfterFinished': 5400.0})])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await deployerClient.run_workflow(app_name='mnist', \n",
    "                                  team_name='dataengineer',\n",
    "                                  workflow = build_app.workflows[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Online Inference (TBD)\n",
    "Online workflow(workflow[1]:online-inference) is defined by dataengineer, first dataengineer should deploy the workflow as services by using seldon, then client could send request to get the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await deployerClient.run_workflow(app_name='mnist', \n",
    "                                  team_name='dataengineer',\n",
    "                                  workflow = build_app.workflows[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  \n",
    "### Step8: Clean scanflow environment\n",
    "  \n",
    "  1. delete environment\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-May-21 18:17:45 -  INFO - [++] Stopping agent: [tracker].\n",
      "27-May-21 18:17:45 -  INFO - delete_deployment true\n",
      "27-May-21 18:17:45 -  INFO - delete_service true\n",
      "27-May-21 18:17:45 -  INFO - [++] Stopping agent: [checker].\n",
      "27-May-21 18:17:45 -  INFO - delete_deployment true\n",
      "27-May-21 18:17:45 -  INFO - delete_service true\n",
      "27-May-21 18:17:45 -  INFO - [++] Stopping agent: [planner].\n",
      "27-May-21 18:17:45 -  INFO - delete_deployment true\n",
      "27-May-21 18:17:45 -  INFO - delete_service true\n",
      "27-May-21 18:17:45 -  INFO - [++] Stopping agent: [executor].\n",
      "27-May-21 18:17:45 -  INFO - delete_deployment true\n",
      "27-May-21 18:17:45 -  INFO - delete_service true\n",
      "27-May-21 18:17:45 -  INFO - [++] Stopping tracker: [scanflow-tracker].\n",
      "27-May-21 18:17:45 -  INFO - delete_deployment true\n",
      "27-May-21 18:17:45 -  INFO - delete_service true\n",
      "27-May-21 18:17:45 -  INFO - [++]Delete tracker configmap scanflow-tracker-env\n",
      "27-May-21 18:17:45 -  INFO - delete_configmap true\n",
      "27-May-21 18:17:45 -  INFO - [++]Delete client configmap scanflow-client-env\n",
      "27-May-21 18:17:45 -  INFO - delete_configmap true\n",
      "27-May-21 18:17:45 -  INFO - [++]Delete s3 secret scanflow-secret\n",
      "27-May-21 18:17:45 -  INFO - delete_secret true\n",
      "27-May-21 18:17:45 -  INFO - [++]Delete rolebinding default-admin\n",
      "27-May-21 18:17:45 -  INFO - delete_rolebinding info\n",
      "27-May-21 18:17:45 -  INFO - [++]Delete namespace \"scanflow-mnist-dataengineer\"\n",
      "27-May-21 18:17:45 -  INFO - delete_namespace true\n",
      "27-May-21 18:17:45 -  INFO - delete_pvc true\n",
      "27-May-21 18:17:45 -  INFO - delete_pv true\n"
     ]
    }
   ],
   "source": [
    "await deployerClient.clean_environment(app=build_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
