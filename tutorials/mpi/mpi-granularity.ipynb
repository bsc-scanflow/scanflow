{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mpi manager - granularity plugin\n",
    "\n",
    "\n",
    "- *Steps*\n",
    "    1. Import Scanflow and check the local environment\n",
    "    2. Develop scanflow application (mpi workloads)\n",
    "    3. Build scanflow application\n",
    "    4. Deploy scanflow environment (namespace, agents)\n",
    "    5. ****[RUN MPI Workloads]****\n",
    "        1. mpi job (volcano job)\n",
    "    6. Clean environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "### Step1: Import Scanflow and check the local environment\n",
    "1. import scanflow\n",
    "    - For defining and building scanflow application, we need to import ScanflowClient\n",
    "    - For deploying scanflow application, we need to import ScanflowDeployerClient\n",
    "2. check local environment\n",
    "    - For deploying scanflow application\n",
    "        - If user starts the notebook at local and has the privilege to submit object on Kubernetes. We don't need to configure \"SCANFLOW_SERVER_URI\"\n",
    "        - If user starts the notebook inside Kubernetes pod, or the local user does not have privilege to connect Kubernetes. We need to configure \"SCANFLOW_SERVER_URI\"\n",
    "    - For saving deliverables, we need to configure url of Scanflow-tracker on \"SCANFLOW_TRACKER_URI\" and url of Scanflow-local-tracker on \"SCANFLOW_TRACKER_LOCAL_URI\"\n",
    "    - If Scanflow-tracker is using S3 artifact storage, we need to configure S3 url \"MLFLOW_S3_ENDPOINT_URL\", username \"AWS_ACCESS_KEY_ID\" and password \"AWS_SECRET_ACCESS_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'../..')\n",
    "\n",
    "import scanflow\n",
    "from scanflow.client import ScanflowClient\n",
    "from scanflow.client import ScanflowDeployerClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://172.30.0.50:46666\n",
      "http://172.30.0.50:46667\n",
      "http://172.30.0.50:43447\n",
      "admin\n",
      "admin123\n"
     ]
    }
   ],
   "source": [
    "from scanflow.tools import env\n",
    "print(env.get_env(\"SCANFLOW_SERVER_URI\"))\n",
    "print(env.get_env(\"SCANFLOW_TRACKER_URI\"))\n",
    "#print(env.get_env(\"SCANFLOW_TRACKER_LOCAL_URI\"))\n",
    "print(env.get_env(\"MLFLOW_S3_ENDPOINT_URL\"))\n",
    "print(env.get_env(\"AWS_ACCESS_KEY_ID\"))\n",
    "print(env.get_env(\"AWS_SECRET_ACCESS_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Develop scanflow application\n",
    "\n",
    "  1. develop component (mainfile.yaml)\n",
    "  2. define scanflow workflows (MPIWorkload, Workflow)\n",
    "  3. define agents to supervise the workflows\n",
    "  4. define scanflow application\n",
    "  ```bash\n",
    "     Application\n",
    "        - List: Workflow\n",
    "                - MPIWorkload\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Develop scanflow workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App folder\n",
    "scanflow_path = \"/gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow\"\n",
    "app_dir = os.path.join(scanflow_path, \"examples/mpi/dataengineer\")\n",
    "app_name = \"mpi\"\n",
    "team_name = \"dataengineer\"\n",
    "\n",
    "# scanflow client\n",
    "client = ScanflowClient(\n",
    "              #if you defined \"SCANFLOW_SERVER_URI\", you dont need to provide this\n",
    "              #scanflow_server_uri=\"http://172.30.0.50:46666\",\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpi workloads\n",
    "mpi1 = client.ScanflowMPIWorkload(name='hpccfft',\n",
    "                                  mainfile='hpccfft.yaml',\n",
    "                                  plugins=['granularity'],\n",
    "                                  characteristic='memory',\n",
    "                                  nTasks=16,\n",
    "                                  nNodes=4,)\n",
    "#workflow\n",
    "workflowhpccfft = client.ScanflowWorkflow(type='mpi',\n",
    "                                       name='hpccfft',\n",
    "                                       nodes=[mpi1],\n",
    "                                       output_dir = \"/home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mpi workloads\n",
    "# mpi2 = client.ScanflowMPIWorkload(name='hpccdgemm',\n",
    "#                                   mainfile='hpccdgemm.yaml',\n",
    "#                                   plugins=['granularity'],\n",
    "#                                   characteristic='cpu',\n",
    "#                                   nTasks=16,\n",
    "#                                   nNodes=4,)\n",
    "# #workflow\n",
    "# workflowhpccdgemm = client.ScanflowWorkflow(type='mpi',\n",
    "#                                        name='hpccdgemm',\n",
    "#                                        nodes=[mpi2],\n",
    "#                                        output_dir = \"/home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#planner\n",
    "planner = client.ScanflowAgent(name='planner',\n",
    "                              template='planner',\n",
    "                              dockerfile='Dockerfile_fortest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Define scanflow application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = client.ScanflowApplication(app_name = app_name,\n",
    "                                 app_dir = app_dir,\n",
    "                                 team_name = team_name,\n",
    "                                 workflows=[workflowhpccfft],\n",
    "                                 agents=[planner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03-Mar-22 17:30:33 -  INFO - workflow hpccfft: {'name': 'hpccfft', 'nodes': [{'name': 'hpccfft', 'node_type': 'mpi', 'mainfile': 'hpccfft.yaml', 'plugins': ['granularity'], 'characteristic': 'memory', 'nTasks': 16, 'nNodes': 4, 'nCpuPerTask': 1, 'masterName': 'mpimaster', 'workerName': 'mpiworker', 'oversubscribe': False, 'body': None}], 'edges': None, 'type': 'mpi', 'resources': None, 'affinity': None, 'kedaSpec': None, 'hpaSpec': None, 'output_dir': '/home'}\n",
      "03-Mar-22 17:30:33 -  INFO - Scanflowagent-planner: {'name': 'planner', 'template': 'planner', 'sensors': None, 'dockerfile': 'Dockerfile_fortest', 'image': None}\n"
     ]
    }
   ],
   "source": [
    "dic = app.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "### Step3: Build scanflow application (local)\n",
    "   \n",
    "  1. build images for Executor -> save to image registry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03-Mar-22 17:30:36 -  INFO - Building image 172.30.0.49:5000/planner-agent\n"
     ]
    }
   ],
   "source": [
    "build_app = client.build_ScanflowApplication(app = app, trackerPort=46672)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03-Mar-22 17:30:38 -  INFO - workflow hpccfft: {'name': 'hpccfft', 'nodes': [{'name': 'hpccfft', 'node_type': 'mpi', 'mainfile': 'hpccfft.yaml', 'plugins': ['granularity'], 'characteristic': 'memory', 'nTasks': 16, 'nNodes': 4, 'nCpuPerTask': 1, 'masterName': 'mpimaster', 'workerName': 'mpiworker', 'oversubscribe': False, 'body': {'apiVersion': 'batch.volcano.sh/v1alpha1', 'kind': 'Job', 'metadata': {'name': 'hpccfft'}, 'spec': {'schedulerName': 'volcano', 'plugins': {'ssh': [], 'svc': []}, 'tasks': [{'replicas': 1, 'name': 'mpimaster', 'policies': [{'event': 'TaskCompleted', 'action': 'CompleteJob'}], 'template': {'spec': {'containers': [{'command': ['/bin/sh', '-c', 'MPI_HOST=\"/etc/volcano/mpi/HOSTFILE\";\\necho `cat ${MPI_HOST}`\\nmkdir -p /var/run/sshd; /usr/sbin/sshd;\\ncp /opt/results/hpccinf.txt /home;\\nsleep 60;\\nmpirun --allow-run-as-root --hostfile ${MPI_HOST} --nooversubscribe --mca mpi_yield_when_idle 0 --mca btl ^openib,uct --mca pml ucx --display-devel-map --display-allocation --report-bindings -np 16  /opt/HPCC1.5.0-MPI/bin/hpccfft > hpccfft-2.log 2>&1;\\nmv hpccoutf.txt hpccfft-2.out;\\n'], 'image': 'mpinetworktrace', 'name': 'mpimaster', 'ports': [{'containerPort': 22, 'name': 'mpijob-port'}], 'workingDir': '/home', 'imagePullPolicy': 'IfNotPresent'}], 'restartPolicy': 'OnFailure'}}}, {'replicas': 1, 'name': 'mpiworker', 'template': {'spec': {'containers': [{'command': ['/bin/sh', '-c', 'cp /opt/results/hpccinf.txt /home;\\nmkdir -p /var/run/sshd; /usr/sbin/sshd -D;\\n'], 'image': 'mpinetworktrace', 'name': 'mpiworker', 'ports': [{'containerPort': 22, 'name': 'mpijob-port'}], 'workingDir': '/home', 'imagePullPolicy': 'IfNotPresent'}], 'restartPolicy': 'OnFailure'}}}]}}}], 'edges': None, 'type': 'mpi', 'resources': None, 'affinity': None, 'kedaSpec': None, 'hpaSpec': None, 'output_dir': '/home'}\n",
      "03-Mar-22 17:30:38 -  INFO - Scanflowagent-planner: {'name': 'planner', 'template': 'planner', 'sensors': None, 'dockerfile': 'Dockerfile_fortest', 'image': '172.30.0.49:5000/planner-agent:latest'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'app_name': 'mpi',\n",
       " 'app_dir': '/gpfs/bsc_home/xpliu/pv/jupyterhubpeini/scanflow/examples/mpi/dataengineer',\n",
       " 'team_name': 'dataengineer',\n",
       " 'workflows': [{'name': 'hpccfft',\n",
       "   'nodes': [{'name': 'hpccfft',\n",
       "     'node_type': 'mpi',\n",
       "     'mainfile': 'hpccfft.yaml',\n",
       "     'plugins': ['granularity'],\n",
       "     'characteristic': 'memory',\n",
       "     'nTasks': 16,\n",
       "     'nNodes': 4,\n",
       "     'nCpuPerTask': 1,\n",
       "     'masterName': 'mpimaster',\n",
       "     'workerName': 'mpiworker',\n",
       "     'oversubscribe': False,\n",
       "     'body': {'apiVersion': 'batch.volcano.sh/v1alpha1',\n",
       "      'kind': 'Job',\n",
       "      'metadata': {'name': 'hpccfft'},\n",
       "      'spec': {'schedulerName': 'volcano',\n",
       "       'plugins': {'ssh': [], 'svc': []},\n",
       "       'tasks': [{'replicas': 1,\n",
       "         'name': 'mpimaster',\n",
       "         'policies': [{'event': 'TaskCompleted', 'action': 'CompleteJob'}],\n",
       "         'template': {'spec': {'containers': [{'command': ['/bin/sh',\n",
       "              '-c',\n",
       "              'MPI_HOST=\"/etc/volcano/mpi/HOSTFILE\";\\necho `cat ${MPI_HOST}`\\nmkdir -p /var/run/sshd; /usr/sbin/sshd;\\ncp /opt/results/hpccinf.txt /home;\\nsleep 60;\\nmpirun --allow-run-as-root --hostfile ${MPI_HOST} --nooversubscribe --mca mpi_yield_when_idle 0 --mca btl ^openib,uct --mca pml ucx --display-devel-map --display-allocation --report-bindings -np 16  /opt/HPCC1.5.0-MPI/bin/hpccfft > hpccfft-2.log 2>&1;\\nmv hpccoutf.txt hpccfft-2.out;\\n'],\n",
       "             'image': 'mpinetworktrace',\n",
       "             'name': 'mpimaster',\n",
       "             'ports': [{'containerPort': 22, 'name': 'mpijob-port'}],\n",
       "             'workingDir': '/home',\n",
       "             'imagePullPolicy': 'IfNotPresent'}],\n",
       "           'restartPolicy': 'OnFailure'}}},\n",
       "        {'replicas': 1,\n",
       "         'name': 'mpiworker',\n",
       "         'template': {'spec': {'containers': [{'command': ['/bin/sh',\n",
       "              '-c',\n",
       "              'cp /opt/results/hpccinf.txt /home;\\nmkdir -p /var/run/sshd; /usr/sbin/sshd -D;\\n'],\n",
       "             'image': 'mpinetworktrace',\n",
       "             'name': 'mpiworker',\n",
       "             'ports': [{'containerPort': 22, 'name': 'mpijob-port'}],\n",
       "             'workingDir': '/home',\n",
       "             'imagePullPolicy': 'IfNotPresent'}],\n",
       "           'restartPolicy': 'OnFailure'}}}]}}}],\n",
       "   'edges': None,\n",
       "   'type': 'mpi',\n",
       "   'resources': None,\n",
       "   'affinity': None,\n",
       "   'kedaSpec': None,\n",
       "   'hpaSpec': None,\n",
       "   'output_dir': '/home'}],\n",
       " 'agents': [{'name': 'planner',\n",
       "   'template': 'planner',\n",
       "   'sensors': None,\n",
       "   'dockerfile': 'Dockerfile_fortest',\n",
       "   'image': '172.30.0.49:5000/planner-agent:latest'}],\n",
       " 'tracker': {'image': '172.30.0.49:5000/scanflow-tracker', 'nodePort': 46672}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_app.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4: Deploy scanflow environment (local/incluster)\n",
    "  \n",
    "  1. Create k8s environment\n",
    "        - create namespace\n",
    "        - create RBAC, secret, configmap, PV, PVC\n",
    "        \n",
    "  2. Deploy scanflow-local-tracker (deployment, service)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03-Mar-22 17:31:45 -  INFO - loading kubernetes configuration from /gpfs/bsc_home/xpliu/.kube/config\n",
      "03-Mar-22 17:31:45 -  INFO - found local kubernetes configuration\n"
     ]
    }
   ],
   "source": [
    "deployerClient = ScanflowDeployerClient(user_type=\"local\",\n",
    "                                        deployer=\"volcano\",\n",
    "                                        k8s_config_file=\"/gpfs/bsc_home/xpliu/.kube/config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03-Mar-22 16:41:45 -  INFO - [++]Creating env\n",
      "03-Mar-22 16:41:45 -  INFO - [++]Creating namespace \"scanflow-mpi-dataengineer\"\n",
      "03-Mar-22 16:41:45 -  INFO - create_namespace true\n",
      "03-Mar-22 16:41:45 -  INFO - [++]Creating Role for 'default service account'\n",
      "03-Mar-22 16:41:45 -  INFO - create_rolebinding info\n",
      "03-Mar-22 16:41:45 -  INFO - [++]Creating s3 secret {'AWS_ACCESS_KEY_ID': 'admin', 'AWS_SECRET_ACCESS_KEY': 'admin123', 'MLFLOW_S3_ENDPOINT_URL': 'http://minio.minio-system.svc.cluster.local:9000', 'AWS_ENDPOINT_URL': 'http://minio.minio-system.svc.cluster.local:9000'}\n",
      "03-Mar-22 16:41:45 -  INFO - create_secret true\n",
      "03-Mar-22 16:41:45 -  INFO - [++]Creating tracker configmap {'TRACKER_STORAGE': 'postgresql://scanflow:scanflow123@postgresql-service.postgresql.svc.cluster.local/scanflow-mpi-dataengineer', 'TRACKER_ARTIFACT': 's3://scanflow/scanflow-mpi-dataengineer'}\n",
      "03-Mar-22 16:41:45 -  INFO - create_configmap true\n",
      "03-Mar-22 16:41:45 -  INFO - [++]Creating client configmap {'SCANFLOW_TRACKER_URI': 'http://scanflow-tracker-service.scanflow-system.svc.cluster.local', 'SCANFLOW_SERVER_URI': 'http://scanflow-server-service.scanflow-system.svc.cluster.local', 'SCANFLOW_TRACKER_LOCAL_URI': 'http://scanflow-tracker.scanflow-mpi-dataengineer.svc.cluster.local'}\n",
      "03-Mar-22 16:41:45 -  INFO - create_configmap true\n",
      "03-Mar-22 16:41:45 -  INFO - [+] Starting local tracker: [scanflow-tracker].\n",
      "03-Mar-22 16:41:45 -  INFO - create_deployment true \n",
      "03-Mar-22 16:41:45 -  INFO - [+] Created tracker Deployment True\n",
      "03-Mar-22 16:41:45 -  INFO - create_service true\n",
      "03-Mar-22 16:41:45 -  INFO - [+] Created tracker Service True\n",
      "03-Mar-22 16:41:45 -  INFO - [TEMPO: Because we dont have scanflow pip install now, we need to mount scanflow]\n",
      "03-Mar-22 16:41:45 -  INFO - create_pv true\n",
      "03-Mar-22 16:41:45 -  INFO - create_pvc true\n",
      "03-Mar-22 16:41:45 -  INFO - create_deployment true \n",
      "03-Mar-22 16:41:45 -  INFO - [+] Created planner Deployment True\n",
      "03-Mar-22 16:41:45 -  INFO - create_service true\n",
      "03-Mar-22 16:41:45 -  INFO - [+] Created planner Service True\n"
     ]
    }
   ],
   "source": [
    "await deployerClient.create_environment(app=build_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5: ****[RUN MPI Workloads]****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deployerClient1 = ScanflowDeployerClient(user_type=\"autoconfig\",\n",
    "                                        deployer=\"volcano\",\n",
    "                                        scanflow_autoconfig_server_uri = \"http://172.30.0.50:35212/sensors\",\n",
    "                                        k8s_config_file=\"/gpfs/bsc_home/xpliu/.kube/config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03-Mar-22 17:30:46 -  INFO - workflow hpccfft: {'name': 'hpccfft', 'nodes': [{'name': 'hpccfft', 'node_type': 'mpi', 'mainfile': 'hpccfft.yaml', 'plugins': ['granularity'], 'characteristic': 'memory', 'nTasks': 16, 'nNodes': 4, 'nCpuPerTask': 1, 'masterName': 'mpimaster', 'workerName': 'mpiworker', 'oversubscribe': False, 'body': {'apiVersion': 'batch.volcano.sh/v1alpha1', 'kind': 'Job', 'metadata': {'name': 'hpccfft'}, 'spec': {'schedulerName': 'volcano', 'plugins': {'ssh': [], 'svc': []}, 'tasks': [{'replicas': 1, 'name': 'mpimaster', 'policies': [{'event': 'TaskCompleted', 'action': 'CompleteJob'}], 'template': {'spec': {'containers': [{'command': ['/bin/sh', '-c', 'MPI_HOST=\"/etc/volcano/mpi/HOSTFILE\";\\necho `cat ${MPI_HOST}`\\nmkdir -p /var/run/sshd; /usr/sbin/sshd;\\ncp /opt/results/hpccinf.txt /home;\\nsleep 60;\\nmpirun --allow-run-as-root --hostfile ${MPI_HOST} --nooversubscribe --mca mpi_yield_when_idle 0 --mca btl ^openib,uct --mca pml ucx --display-devel-map --display-allocation --report-bindings -np 16  /opt/HPCC1.5.0-MPI/bin/hpccfft > hpccfft-2.log 2>&1;\\nmv hpccoutf.txt hpccfft-2.out;\\n'], 'image': 'mpinetworktrace', 'name': 'mpimaster', 'ports': [{'containerPort': 22, 'name': 'mpijob-port'}], 'workingDir': '/home', 'imagePullPolicy': 'IfNotPresent'}], 'restartPolicy': 'OnFailure'}}}, {'replicas': 1, 'name': 'mpiworker', 'template': {'spec': {'containers': [{'command': ['/bin/sh', '-c', 'cp /opt/results/hpccinf.txt /home;\\nmkdir -p /var/run/sshd; /usr/sbin/sshd -D;\\n'], 'image': 'mpinetworktrace', 'name': 'mpiworker', 'ports': [{'containerPort': 22, 'name': 'mpijob-port'}], 'workingDir': '/home', 'imagePullPolicy': 'IfNotPresent'}], 'restartPolicy': 'OnFailure'}}}]}}}], 'edges': None, 'type': 'mpi', 'resources': None, 'affinity': None, 'kedaSpec': None, 'hpaSpec': None, 'output_dir': '/home'}\n",
      "03-Mar-22 17:30:46 -  INFO - sensors_run_autoconfig_workflow received\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await deployerClient1.run_autoconfig_workflow(app_name='mpi', \n",
    "                                             team_name='dataengineer',\n",
    "                                             workflow = build_app.workflows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03-Mar-22 17:31:49 -  INFO - delete_pvc true\n",
      "03-Mar-22 17:31:49 -  INFO - delete_pv true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await deployerClient.delete_workflow(app_name='mpi', \n",
    "                                  team_name='dataengineer',\n",
    "                                  workflow = build_app.workflows[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  \n",
    "### Step8: Clean scanflow environment\n",
    "  \n",
    "  1. delete environment\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03-Mar-22 16:12:29 -  INFO - [++] Stopping agent: [planner].\n",
      "03-Mar-22 16:12:29 -  ERROR - delete_deployment error\n",
      "03-Mar-22 16:12:29 -  ERROR - delete_service error\n",
      "03-Mar-22 16:12:29 -  INFO - [++] Stopping tracker: [scanflow-tracker].\n",
      "03-Mar-22 16:12:29 -  INFO - delete_deployment true\n",
      "03-Mar-22 16:12:29 -  INFO - delete_service true\n",
      "03-Mar-22 16:12:29 -  INFO - [++]Delete tracker configmap scanflow-tracker-env\n",
      "03-Mar-22 16:12:29 -  INFO - delete_configmap true\n",
      "03-Mar-22 16:12:29 -  INFO - [++]Delete client configmap scanflow-client-env\n",
      "03-Mar-22 16:12:29 -  INFO - delete_configmap true\n",
      "03-Mar-22 16:12:29 -  INFO - [++]Delete s3 secret scanflow-secret\n",
      "03-Mar-22 16:12:29 -  INFO - delete_secret true\n",
      "03-Mar-22 16:12:29 -  INFO - [++]Delete rolebinding default-admin\n",
      "03-Mar-22 16:12:29 -  INFO - delete_rolebinding info\n",
      "03-Mar-22 16:12:29 -  INFO - [++]Delete namespace \"scanflow-mpi-dataengineer\"\n",
      "03-Mar-22 16:12:29 -  INFO - delete_namespace true\n",
      "03-Mar-22 16:12:29 -  INFO - delete_pvc true\n",
      "03-Mar-22 16:12:29 -  INFO - delete_pv true\n"
     ]
    }
   ],
   "source": [
    "await deployerClient.clean_environment(app=build_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
